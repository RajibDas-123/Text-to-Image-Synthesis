import streamlit as st
from PIL import Image
import numpy as np
import io
import random
from torchvision import transforms
from diffusers import StableDiffusionPipeline
from GAN.utils import loadGloveModel, return_images
from GAN.models import build_generator_func
import torch
import tensorflow as tf

gan_flower_path = "GAN/gan-flower-model/text_to_image_generator_character.h5" 
gan_cub_path = "GAN/gan-cub-model/text_to_image_generator_character.h5" 
diff_cub_path = "Diffusion/cub-model" 
diff_flower_path = "Diffusion/flower-model"

PREVIEW_ROWS = 1
PREVIEW_COLS = 1
PREVIEW_MARGIN = 0
GENERATE_SQUARE = 64

torch.mps.empty_cache()


train_transforms = transforms.Compose(
    [
        transforms.Resize(64, interpolation=transforms.InterpolationMode.BILINEAR),
    ]
)

def test_image(generator, glove_embeddings, text,num):
    test_embeddings = np.zeros((1,300),dtype=np.float32)

    x = text.lower()
    x = x.replace(" ","")
    count = 0
    for t in x:
        try:
            test_embeddings[0] += glove_embeddings[t]
            count += 1
        except:
            pass
    test_embeddings[0] /= count
    test_embeddings =  np.repeat(test_embeddings,[1],axis=0)
    noise = tf.random.normal([1, 100])
    return return_images(generator, num,noise,test_embeddings, PREVIEW_MARGIN, PREVIEW_ROWS, PREVIEW_COLS,GENERATE_SQUARE)


def generate_diffusion(prompt, category):
    buf = io.BytesIO()
    if category == "Flower":
        pipe_flower = StableDiffusionPipeline.from_pretrained(diff_flower_path, torch_dtype=torch.float16).to('mps')
        train_transforms(pipe_flower(prompt).images[0])
    else:
        pipe_cub = StableDiffusionPipeline.from_pretrained(diff_cub_path, torch_dtype=torch.float16).to('mps')
        train_transforms(pipe_cub(prompt).images[0]).save(buf, format='PNG')
    byte_im = buf.getvalue() 
    return byte_im

def generate_gan(prompt, category):
    glove_embeddings = loadGloveModel("/Users/rajibdas/Workspace/UB/CV/data/glove.6B.300d.txt")
    buf = io.BytesIO()
    if category == "Flower":
        generator_flower = build_generator_func(100,300, 3)
        generator_flower.load_weights(gan_flower_path)
        test_image(generator_flower, glove_embeddings, prompt, 1)
    else:
        generator_cub = build_generator_func(100,300, 3)
        generator_cub.load_weights(gan_cub_path)
        test_image(generator_cub, glove_embeddings, prompt, 1).save(buf, format="PNG")
    byte_im = buf.getvalue() 
    return byte_im

st.title('Text to Image Generation')

category = st.selectbox("Choose a category to generate images:", ["Flower", "Bird"])
prompt = st.text_input("Enter a prompt to generate images:", "")

if st.button('Generate'):
    if prompt:
       
        image_gan = generate_gan(prompt, category)
        image_diffusion = generate_diffusion(prompt, category)

        
        col1, col2 = st.columns(2)

        
        with col1:
            st.image(image_gan, caption='Generated by GAN', use_column_width=True)

        
        with col2:
            st.image(image_diffusion, caption='Generated by Diffusion Model', use_column_width=True)
    else:
        st.write("Please enter a prompt.")
